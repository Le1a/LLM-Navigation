对于大语言模型(LLM)来说,System Prompt 和 User Prompt 在使用场景上有明显的区别:

## System Prompt
System Prompt 是提供给模型的系统级指令,主要用于:
- 1. 定义模型的身份和角色:设定模型应该以什么样的身份来回答问题（如专家、助手、特定角色等
- 2. 设置行为准则和限制:指定模型应该遵循的规则、伦理边界和回答风格
- 3. 提供背景知识:为模型提供特定领域的专业知识或上下文信息
- 4.设置输出格式:规定模型应该以什么样的格式（如Markdown、JSON等）来组织回答
- 5. 配置模型偏好:设置语言、时区、日期格式等全局偏好
System Prompt 对用户通常是不可见的,由系统开发者或应用程序设置,在整个对话过程中保持一致

## User Prompt
User Prompt 是用户直接输入的内容,主要用于:
- 1. 提出具体问题或请求:用户想要解决的实际问题
- 2. 提供特定任务的输入:如需要总结的文本、需要翻译的内容等
- 3. 与模型进行交互式对话:根据模型的回答进行追问或提供额外信息
- 4. 修改或调整对话方向:根据需要引导对话朝特定方向发展
- 5. 提供即时反馈:对模型的回答进行评价或要求修改
User Prompt 是对话的核心内容,直接决定了模型需要处理的具体任务

## 主要区别
- 持久性:System Prompt 在整个会话中持续有效,而User Prompt 通常只针对当前交互
- 可见性:System Prompt 对用户通常不可见,User Prompt 是用户自己输入的内容
- 控制级别:System Prompt 设置全局行为和能力边界,User Prompt 控制具体任务
- 优先级:当 System Prompt 和 User Prompt 有冲突时,通常 User Prompt 的指令会优先被执行